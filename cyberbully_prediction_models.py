# -*- coding: utf-8 -*-
"""IMT575 - Prediction Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AK7dgENrEXLq0PGyL_w_yo_GEx3X-ccE

Unimodal Cyberbullying Detection and NLP Analysis

Shan Ming Gao, CP Chan, Melody Chang, Kelly Liu
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from gensim.models import KeyedVectors
import nltk
from nltk.tokenize import TweetTokenizer
from nltk.corpus import stopwords
import numpy as np

df = pd.read_csv('cyberbully.csv')

# Define the tokenize function of the tweets from the raw data
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
tokenizer = TweetTokenizer()

def preprocess_tweet(text):
    tokens = tokenizer.tokenize(text.lower())
    tokens = [token for token in tokens if token.isalpha() and not token in stop_words]
    return tokens

# Load pre-trained word2vec model from the google news

import gensim.downloader as api

word2vec_model = api.load("word2vec-google-news-300")

# Define the function from tweets to word embeddings

def tweet_to_embedding(tweet, model):
    words = preprocess_tweet(tweet)
    word_vectors = [model[word] for word in words if word in model]
    if len(word_vectors) == 0:
        return np.zeros(model.vector_size)
    tweet_embedding = np.mean(word_vectors, axis=0)
    return tweet_embedding

# Convert each tweet from the column 'text' to an embedding and store the result in a new column 'embedding'
df['embedding'] = df['text'].apply(lambda x: tweet_to_embedding(x, word2vec_model))

# Save as a new csv
df.to_csv('tweets_embeddings.csv', index=False)

# Tensorflow

from sklearn.model_selection import train_test_split

# input X is 'embedding' column and the output y is the 'label' column
# Convert X into a list
X = np.array(df['embedding'].tolist())
y = df['label'].values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Initialize the constructor
model = Sequential()

# Add an input layer
model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))

# Add one hidden layer
model.add(Dense(128, activation='relu'))

# Add an output layer
num_classes = len(np.unique(y_train))  # Determine how many unique classes are there
if num_classes == 2:
    model.add(Dense(1, activation='sigmoid'))  # Use sigmoid for binary classification
else:
    model.add(Dense(num_classes, activation='softmax'))  # Use softmax for multi-class classification

if num_classes == 2:
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
else:
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# MLPClassifier

from sklearn.neural_network import MLPClassifier

# Initialize the MLPClassifier
# Here you can specify the architecture. For example, two hidden layers with 100 neurons each:
mlp = MLPClassifier(hidden_layer_sizes=(100, 100), activation='relu', solver='adam', max_iter=300)

# Train the model
mlp.fit(X_train, y_train)

# After fitting the model, you can check if the training process has converged
print("Training converged:", mlp.n_iter_)  # Shows the number of iterations until convergence

from sklearn.metrics import accuracy_score, classification_report

# Predict labels for the test set
y_pred = mlp.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Detailed classification report
print(classification_report(y_test, y_pred))

# Logistic Regression

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report

# Assuming your data is already loaded into X and y
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the logistic regression model
log_reg = LogisticRegression(solver='liblinear', penalty='l2')  # 'liblinear' is good for small datasets

# Train the model
log_reg.fit(X_train, y_train)

print("Number of iterations:", log_reg.n_iter_)

# Predict labels for the test set
y_pred_lr = log_reg.predict(X_test)

# Calculate accuracy
accuracy_lr = accuracy_score(y_test, y_pred_lr)
print("Logistic Regression Accuracy:", accuracy_lr)

# Detailed classification report
print("Logistic Regression Classification Report:")
print(classification_report(y_test, y_pred_lr))


print('Logistic Regression Precision:', precision_score(y_test, y_pred_lr,average='weighted'))
print('Logistic Regression Recall:', recall_score(y_test, y_pred_lr,average='weighted'))
print('Logistic Regression Accuracy:F1_score:', f1_score(y_test, y_pred_lr,average='weighted'))

#Ref: https://medium.com/@Doug-Creates/plotting-scikit-learn-classification-report-for-analysis-0229447fe232

import matplotlib.pyplot as plt
import seaborn as sns

class_report = classification_report(y_test, y_pred_lr, output_dict=True)

def visualize_report(report):
    # Define custom colors
    colors = ['#ffdfdf', '#dfffff', '#dfffdf', '#dfdfff', '#ffdfff', '#ffffdf']

    # Extracting metrics for each class
    metrics = ['precision', 'recall', 'f1-score', 'support']
    data = {metric: [] for metric in metrics}
    labels = []

    # Include class-specific metrics
    for cls, metrics_values in report.items():
        if cls.isdigit() or cls in ['ethnicity/race', 'gender/sexual', 'not_cyberbullying', 'religion']:
            labels.append(cls)
            for metric in metrics:
                data[metric].append(metrics_values.get(metric, None))

    # Convert data to DataFrame for easy plotting
    df = pd.DataFrame(data, index=labels)

    # Creating subplots for each metric
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    for ax, metric in zip(axes, metrics[:-1]):  # Exclude 'support' for plotting
        sns.barplot(ax=ax, x=df.index, y=metric, data=df, palette=colors)
        ax.set_title(f'{metric.capitalize()} by Category')
        ax.set_ylim(0, 1.1)
        ax.set_xlabel('Category')
        ax.set_ylabel(metric.capitalize())

    plt.tight_layout()
    plt.show()

visualize_report(class_report)

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix


# Initialize and train the SVM classifier
svm_model = SVC()
svm_model.fit(X_train, y_train)

# Make predictions on the test set
svm_preds = svm_model.predict(X_test)

# Calculate and print accuracy, precision, recall, and F1-score
accuracy = accuracy_score(y_test, svm_preds)
precision = precision_score(y_test, svm_preds, average='weighted')
recall = recall_score(y_test, svm_preds, average='weighted')
f1 = f1_score(y_test, svm_preds, average='weighted')

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)


# Detailed classification report
print("Logistic Regression Classification Report:")
print(classification_report(y_test, svm_preds))

# Classification report for SVM classification model
svm_report = classification_report(y_test, svm_preds)
print(svm_report)

# SVM Confusion Matrix
from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, svm_preds)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('Actual labels')
plt.title('Confusion Matrix')
plt.show()

# Model Comparisons

models = ['MLPClassifier', 'Tensorflow', 'Logistic Regression', 'SVM']
accuracy = [0.98, 0.98, 0.94, 0.98]
precision = [0.98, 0.98, 0.94, 0.98]
recall = [0.98, 0.98, 0.94, 0.98]
f1 = [0.98, 0.98, 0.94, 0.98]

bar_width = 0.2

# Plot
r1 = range(len(models))
r2 = [x + bar_width for x in r1]
r3 = [x + bar_width for x in r2]
r4 = [x + bar_width for x in r3]

# Plot
plt.figure(figsize=(10, 6))

plt.bar(r1, accuracy, color='#ffdfdf', width=bar_width, label='Accuracy')
plt.bar(r2, precision, color='#dfffff', width=bar_width, label='Precision')
plt.bar(r3, recall, color='#dfffdf', width=bar_width, label='Recall')
plt.bar(r4, f1, color='#dfdfff',width=bar_width, label='F1')

# Add xticks on the middle of the group bars

plt.xticks([r + bar_width*1.5 for r in range(len(models))], models)
plt.title('Models Comparison')
plt.ylabel('Performance')
plt.ylim(0.9, 1)
plt.legend()

plt.show()
